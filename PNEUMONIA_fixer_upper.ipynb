{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/Users/jeffreyscruggs/Desktop/DataSets/chest_xray/train'\n",
    "validation_dir = '/Users/jeffreyscruggs/Desktop/DataSets/chest_xray/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_NORMAL_dir = os.path.join(train_dir, 'NORMAL') # directory with our training elephant pictures\n",
    "train_PNEUMONIA_dir = os.path.join(train_dir, 'PNEUMONIA') # directory with our training tiger pictures\n",
    "validation_NORMAL_dir = os.path.join(validation_dir, 'NORMAL') # directory with our validation elephant pictures\n",
    "validation_PNEUMONIA_dir = os.path.join(validation_dir, 'PNEUMONIA') # directory with our validation tiger pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training NORMAL images: 1341\n",
      "total training PNEUMONIA images: 3875\n",
      "total validation NORMAL images: 234\n",
      "total validation PNEUMONIA images: 390\n",
      "--\n",
      "Total training images: 5216\n",
      "Total validation images: 624\n"
     ]
    }
   ],
   "source": [
    "num_NORMAL_tr = len(os.listdir(train_NORMAL_dir))\n",
    "num_PNEUMONIA_tr = len(os.listdir(train_PNEUMONIA_dir))\n",
    "num_NORMAL_val = len(os.listdir(validation_NORMAL_dir))\n",
    "num_PNEUMONIA_val = len(os.listdir(validation_PNEUMONIA_dir))\n",
    "total_train = num_NORMAL_tr + num_PNEUMONIA_tr\n",
    "total_val = num_NORMAL_val + num_PNEUMONIA_val\n",
    "print('total training NORMAL images:', num_NORMAL_tr)\n",
    "print('total training PNEUMONIA images:', num_PNEUMONIA_tr)\n",
    "\n",
    "print('total validation NORMAL images:', num_NORMAL_val)\n",
    "print('total validation PNEUMONIA images:', num_PNEUMONIA_val)\n",
    "print(\"--\")\n",
    "print(\"Total training images:\", total_train)\n",
    "print(\"Total validation images:\", total_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 5\n",
    "IMG_HEIGHT = 150\n",
    "IMG_WIDTH = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our training data\n",
    "validation_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
    " directory=train_dir,\n",
    " shuffle=True,\n",
    " target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    " class_mode='binary')\n",
    "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
    " directory=validation_dir,\n",
    " target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    " class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    " Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
    " MaxPooling2D(),\n",
    " Conv2D(32, 3, padding='same', activation='relu'),\n",
    " MaxPooling2D(),\n",
    " Conv2D(64, 3, padding='same', activation='relu'),\n",
    " MaxPooling2D(),\n",
    " Flatten(),\n",
    " Dense(512, activation='relu'),\n",
    " Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    " loss='binary_crossentropy',\n",
    " metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 150, 150, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 75, 75, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 75, 75, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 37, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 37, 37, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 20736)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               10617344  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 10,641,441\n",
      "Trainable params: 10,641,441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "40/40 [==============================] - 108s 3s/step - loss: 0.3683 - accuracy: 0.8365 - val_loss: 0.4783 - val_accuracy: 0.8320\n",
      "Epoch 2/5\n",
      "40/40 [==============================] - 108s 3s/step - loss: 0.1175 - accuracy: 0.9560 - val_loss: 0.9520 - val_accuracy: 0.7246\n",
      "Epoch 3/5\n",
      "40/40 [==============================] - 109s 3s/step - loss: 0.0850 - accuracy: 0.9674 - val_loss: 0.6725 - val_accuracy: 0.7695\n",
      "Epoch 4/5\n",
      "40/40 [==============================] - 109s 3s/step - loss: 0.0774 - accuracy: 0.9727 - val_loss: 1.0122 - val_accuracy: 0.7422\n",
      "Epoch 5/5\n",
      "40/40 [==============================] - 113s 3s/step - loss: 0.0691 - accuracy: 0.9744 - val_loss: 1.0874 - val_accuracy: 0.7363\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    " train_data_gen,\n",
    " steps_per_epoch= total_train // batch_size,\n",
    " epochs=epochs,\n",
    " validation_data= val_data_gen,\n",
    " validation_steps= total_val // batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/jeffreyscruggs/opt/anaconda3/envs/classifier/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: PNEUMONIA_Beta/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('PNEUMONIA_Beta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NORMAL': 0, 'PNEUMONIA': 1}\n"
     ]
    }
   ],
   "source": [
    "print(train_data_gen.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from PIL import Image, ImageFont, ImageDraw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]]\n"
     ]
    }
   ],
   "source": [
    "test_image = image.load_img('/Users/jeffreyscruggs/Desktop/DataSets/chest_xray/val/NORMAL/NORMAL2-IM-1437-0001.jpeg', target_size = (150,150))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = model.predict(test_image)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
